{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are five players tied for fourth place, all with a total score of 137.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-7-lotnlgqwen", "annotations": [{"type": 0, "text": "There", "start": 0, "id": "vvnve0m2"}, {"type": 0, "text": "There are five players tied for fourth place, all with a total score of 137.", "start": 0, "id": "opqiz3pb"}, {"type": 0, "text": "tied", "start": 23, "id": "toks3d2h"}, {"type": 0, "text": "fourth", "start": 32, "id": "liy9y5x5"}, {"type": 0, "text": "five", "start": 10, "id": "5nsd5qjf"}, {"type": 0, "text": "are", "start": 6, "id": "4ofgidrf"}, {"type": 0, "text": "players", "start": 15, "id": "d1gd2yap"}, {"type": 0, "text": "for", "start": 28, "id": "ai01s10t"}, {"type": 0, "text": "place,", "start": 39, "id": "nz9gsx3k"}, {"type": 0, "text": "all", "start": 46, "id": "nvjcgugz"}, {"type": 0, "text": "with", "start": 50, "id": "du7qxivt"}, {"type": 0, "text": "a", "start": 55, "id": "jkyahzj6"}, {"type": 0, "text": "total", "start": 57, "id": "k3hem86r"}, {"type": 0, "text": "score", "start": 63, "id": "pfzsvg7z"}, {"type": 0, "text": "of", "start": 69, "id": "bu4d5qva"}, {"type": 0, "text": "137.", "start": 72, "id": "esxlb6xh"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826209, "time_last_accessed": 1752825975}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "The average score of players tied for ninth place is 141, which is 1 under par.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-10-lotnlgqwen", "annotations": [{"type": 3, "text": "The average score of players tied for", "start": 0, "id": "1kgpksq6"}, {"type": 3, "text": "for ninth place is 141, which is 1 under par.", "start": 34, "id": "92778q7x"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826286, "time_last_accessed": 1752826209}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "The average to_par score among all participants is -4.2.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-3-lotnlgdeepseek", "annotations": [{"type": 3, "text": "to_par", "start": 12, "id": "kl5bxd8o"}, {"type": 1, "text": "The average to_par score", "start": 0, "id": "qkbukvv4"}, {"type": 1, "text": "score among all participants is -4.2.", "start": 19, "id": "uvp1zltt"}, {"type": 1, "text": "-4.2.", "start": 51, "id": "21x8xstj"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826340, "time_last_accessed": 1752826286}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Fred Couples and David Tapping tied for fourth place with a score of 137.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-4-lotnlgdeepseek", "annotations": [{"type": 1, "text": "Fred Couples and David Tapping tied for fourth place with a score of 137.", "start": 0, "id": "65ldpj2k"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826369, "time_last_accessed": 1752826340}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "The average score to par of all players listed is approximately -3.5, indicating a generally strong performance across the board.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-18-lotnlgllama", "annotations": [{"type": 1, "text": "The average score to par of all players listed is approximately -3.5, indicating a generally strong performance across the board.", "start": 0, "id": "10sotami"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826411, "time_last_accessed": 1752826369}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Angel Cabrera from Argentina scored 140 strokes in the championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-5-lotnlgdeepseek", "annotations": [{"type": 3, "text": "Angel Cabrera from Argentina scored 140 strokes in the championship.", "start": 0, "id": "xnurcs6l"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826444, "time_last_accessed": 1752826411}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are 8 nations represented at the Biathlon World Championships 2025.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-21-attention", "annotations": [{"type": 1, "text": "There are 8 nations represented at the Biathlon World Championships 2025.", "start": 0, "id": "h8r5w0dc"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826486, "time_last_accessed": 1752826444}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Justin Leonard's score of 135 is better than Jesper Parnevik's score of 136 by 1 stroke.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-8-lotnlgqwen", "annotations": [{"type": 3, "text": "Justin Leonard's score of 135 is better than Jesper Parnevik's score of 136 by 1 stroke.", "start": 0, "id": "kll0lljq"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826514, "time_last_accessed": 1752826486}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Darren Clarke achieves the highest score under par in the tournament with -9.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-16-lotnlgllama", "annotations": [{"type": 3, "text": "Darren Clarke achieves the highest score under par in the tournament with -9.", "start": 0, "id": "jwkh3w4o"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826533, "time_last_accessed": 1752826514}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Darren Clarke achieved the lowest score of 133, making him the leader in the 1997 Open Championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-15-lotnlggemma", "annotations": [{"type": 3, "text": "Darren Clarke achieved the lowest score of 133, making him the leader in the 1997", "start": 0, "id": "rm3hgym6"}, {"type": 3, "text": "leader in the 19", "start": 63, "id": "vazfnvgh"}, {"type": 3, "text": "leader", "start": 63, "id": "lab81t79"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826560, "time_last_accessed": 1752826533}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Fred Couples and David Tapping are tied for fourth place in the tournament.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-13-lotnlggemma", "annotations": [{"type": 3, "text": "Fred Couples and David Tapping are tied for fourth place in the tournament.", "start": 0, "id": "d0mwfoad"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826589, "time_last_accessed": 1752826560}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are eight players from the United States competing in the 1997 Open Championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-14-lotnlggemma", "annotations": [{"type": 3, "text": "There", "start": 0, "id": "o8ocaoa8"}, {"type": 3, "text": "There are eight players from the United States competing in the 1997 Open Championship.", "start": 0, "id": "hw1eblj7"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826630, "time_last_accessed": 1752826589}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are 9 players from the United States participating in the championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-2-lotnlgdeepseek", "annotations": [{"type": 0, "text": "There are 9 players from the United States participating in the championship.", "start": 0, "id": "o2h18qc9"}, {"type": 0, "text": "players", "start": 12, "id": "ozu1e598"}, {"type": 0, "text": "9", "start": 10, "id": "udlm3k0e"}, {"type": 0, "text": "United", "start": 29, "id": "up5wsggb"}, {"type": 0, "text": "States", "start": 36, "id": "nfxpj8wo"}, {"type": 0, "text": "championship.", "start": 64, "id": "dlzsuzpc"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826669, "time_last_accessed": 1752826630}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Darren Clarke achieved the lowest score in the 1997 Open Championship with a total of 133 strokes.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-1-lotnlgdeepseek", "annotations": [{"type": 3, "text": "Darren Clarke achieved the lowest score in the 1997 Open Championship with a total of 133 strokes.", "start": 0, "id": "mclsdt1a"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826691, "time_last_accessed": 1752826669}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Darren Clarke from Northern Ireland achieved the lowest score of 133 at the 1997 Open Championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-6-lotnlgqwen", "annotations": [{"type": 3, "text": "Darren Clarke from Northern Ireland achieved the lowest score of 133 at the 1997 Open Championship.", "start": 0, "id": "xfjzaagd"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826705, "time_last_accessed": 1752826691}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are 6 players from the United States participating in the championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-17-lotnlgllama", "annotations": [{"type": 0, "text": "There are 6 players from the United States participating in the championship.", "start": 0, "id": "rwfnjw1y"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826720, "time_last_accessed": 1752826705}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Justin Leonard has a higher score than Darren Clarke but lower under-par score at -7 compared to Clarke's -9.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-20-lotnlgllama", "annotations": [{"type": 0, "text": "Justin Leonard has a higher score than Darren Clarke but lower under-par score at -7 compared to Clarke's -9.", "start": 0, "id": "r4tkfiss"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826734, "time_last_accessed": 1752826720}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Jesper Parnevik, from Sweden, scored 136 in total with a score of -6 to par.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-19-lotnlgllama", "annotations": [{"type": 3, "text": "Jesper Parnevik, from Sweden, scored 136 in total with a score of -6 to par.", "start": 0, "id": "kn9tdmor"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826752, "time_last_accessed": 1752826734}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Darren Clarke achieved a score of 133 in the 1997 Open Championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-11-lotnlggemma", "annotations": [{"type": 3, "text": "Darren Clarke achieved a score of 133 in the 1997 Open Championship.", "start": 0, "id": "ul6dj43v"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826765, "time_last_accessed": 1752826752}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "Justin Leonard\u2019s score of 135 is higher than Jesper Parnevik\u2019s score of 136.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-12-lotnlggemma", "annotations": [{"type": 3, "text": "Justin Leonard\u2019s score of 135 is higher than Jesper Parnevik\u2019s score of 136.", "start": 0, "id": "m2n64dl9"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826786, "time_last_accessed": 1752826765}
{"dataset": "t2t", "split": "test", "example_idx": 54, "output": "There are five different countries represented in the top ten places at the 1997 Open Championship.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-9-lotnlgqwen", "annotations": [{"type": 3, "text": "There are five different countries represented in the top ten places at the 1997 Open Championship.", "start": 0, "id": "pcknx981"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826809, "time_last_accessed": 1752826786}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Germany won 1 silver medal in the championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-20-freshtabllama", "annotations": [{"type": 3, "text": "Germany won 1 silver medal in the championships.", "start": 0, "id": "ot4x1j5c"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826837, "time_last_accessed": 1752826809}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "France achieved the highest total medal count with 4 medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-11-freshtabgemma", "annotations": [{"type": 3, "text": "France achieved the highest total medal count with 4 medals.", "start": 0, "id": "p3hfe2i6"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826849, "time_last_accessed": 1752826837}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "There are two nations, Germany and Norway, tied with a total of 1 medal each.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-13-freshtabgemma", "annotations": [{"type": 3, "text": "There are two nations, Germany and Norway, tied with a total of 1 medal each.", "start": 0, "id": "sip2b32t"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826866, "time_last_accessed": 1752826849}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "The total number of gold medals awarded in the championships is 6.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-17-freshtabllama", "annotations": [{"type": 3, "text": "The total number of gold medals awarded in the championships is 6.", "start": 0, "id": "4ycacw1z"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826880, "time_last_accessed": 1752826866}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "There are two nations tied for sixth place in the rankings.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-10-freshtabdeepseek", "annotations": [{"type": 3, "text": "There are two", "start": 0, "id": "dd558r94"}, {"type": 3, "text": "two nations tied for sixth place in the rankings.", "start": 10, "id": "ae5ukdic"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826895, "time_last_accessed": 1752826880}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Italy has more gold medals than silver and bronze medals combined.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-18-freshtabllama", "annotations": [{"type": 3, "text": "Italy has more gold medals than silver and bronze medals combined.", "start": 0, "id": "s8hlsylg"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826928, "time_last_accessed": 1752826895}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "There are 8 different nations participating in the 2025 European Running Championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-5-freshtabqwen", "annotations": [{"type": 3, "text": "There are 8 different nations participating in the 2025 European Running Championships.", "start": 0, "id": "vfv0civn"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826944, "time_last_accessed": 1752826928}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "There are 14 shipwrecks recorded in the list of disasters.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-21-attention", "annotations": [{"type": 1, "text": "There are 14 shipwrecks recorded in the list", "start": 0, "id": "irpf0gny"}, {"type": 1, "text": "shipwrecks", "start": 13, "id": "7jrz5g1m"}, {"type": 1, "text": "14", "start": 10, "id": "3b4knu5h"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826967, "time_last_accessed": 1752826944}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Germany and Norway are tied for sixth place in the rankings.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-7-freshtabdeepseek", "annotations": [{"type": 3, "text": "Germany and Norway are tied for sixth place in the rankings.", "start": 0, "id": "v6je8vg5"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752826983, "time_last_accessed": 1752826967}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Spain has more gold medals than bronze medals at the championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-9-freshtabdeepseek", "annotations": [{"type": 3, "text": "Spain has more gold medals than bronze medals at the championships.", "start": 0, "id": "kjyz3toy"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827000, "time_last_accessed": 1752826983}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Belgium is the third-ranked nation in the medal standings with a total of 3 medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-15-freshtabgemma", "annotations": [{"type": 3, "text": "Belgium is the third-ranked nation in the medal standings with a total of 3 medals.", "start": 0, "id": "rw88f0sp"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827013, "time_last_accessed": 1752827000}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "There are 8 nations participating in the 2025 European Running Championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-19-freshtabllama", "annotations": [{"type": 3, "text": "There are 8 nations participating in the", "start": 0, "id": "v4ucakkz"}, {"type": 3, "text": "There are 8 nations participating in the 2025 European Running Champ", "start": 0, "id": "4eaxdxvn"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827038, "time_last_accessed": 1752827013}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "France (FRA) achieved the highest total medal count with 4 medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-1-freshtabqwen", "annotations": [{"type": 3, "text": "France (FRA) achieved the highest total medal count with 4 medals.", "start": 0, "id": "qu2ynb7t"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827050, "time_last_accessed": 1752827038}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Spain (ESP) is the fourth-ranked nation in the 2025 European Running Championships with 1 gold, 1 silver, and no bronze medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-4-freshtabqwen", "annotations": [{"type": 3, "text": "Spain (ESP) is the fourth-ranked nation in the 2025 European Running Championships with 1 gold, 1 silver, and no bronze medals.", "start": 0, "id": "hz341dlk"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827064, "time_last_accessed": 1752827050}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Italy won more gold medals than Belgium, with 2 gold medals each.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-12-freshtabgemma", "annotations": [{"type": 3, "text": "Italy won more gold medals than Belgium, with 2 gold medals each.", "start": 0, "id": "ge9jck5z"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827076, "time_last_accessed": 1752827064}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "France achieves the highest rank in the 2025 European Running Championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-16-freshtabllama", "annotations": [{"type": 3, "text": "France achieves the highest rank in the 2025 European Running Championships.", "start": 0, "id": "cmqzs9px"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827086, "time_last_accessed": 1752827076}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "The total number of gold medals awarded in the championship is 6.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-8-freshtabdeepseek", "annotations": [{"type": 3, "text": "The total number of gold medals awarded in the championship is 6.", "start": 0, "id": "gsmd9gck"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827097, "time_last_accessed": 1752827086}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Slovenia won 1 bronze medal in the 2025 European Running Championships.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-14-freshtabgemma", "annotations": [{"type": 3, "text": "Slovenia won 1 bronze medal in the 2025 European Running Championships.", "start": 0, "id": "59aki6le"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827109, "time_last_accessed": 1752827097}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "The total number of gold, silver, and bronze medals awarded in the 2025 European Running Championships is 6 each, totaling 18 medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-2-freshtabqwen", "annotations": [{"type": 3, "text": "The total number of gold, silver, and bronze medals awarded in the 2025 European Running Championships is 6 each, totaling 18 medals.", "start": 0, "id": "t927shw9"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827126, "time_last_accessed": 1752827109}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "France achieved the highest number of total medals at the 2025 European Running Championships with a total of 4.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-6-freshtabdeepseek", "annotations": [{"type": 3, "text": "France achieved the highest number of total medals at the 2025 European Running Championships with a total of 4.", "start": 0, "id": "lh7jb30i"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827138, "time_last_accessed": 1752827126}
{"dataset": "t2t", "split": "test", "example_idx": 55, "output": "Italy (ITA) has a higher total medal count than Belgium (BEL), despite both countries having the same number of bronze medals.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-3-freshtabqwen", "annotations": [{"type": 0, "text": "Italy (ITA) has a higher total medal count than Belgium (BEL), despite both countries having the same number of bronze medals.", "start": 0, "id": "zzwvtedd"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827166, "time_last_accessed": 1752827138}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister achieved the highest number of votes among all candidates in the first round with 122 votes.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-19-diversellama", "annotations": [{"type": 3, "text": "Martin Pfister achieved the highest number of votes among all candidates in the first round with 122 votes.", "start": 0, "id": "456fr5pg"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827201, "time_last_accessed": 1752827166}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Markus Ritter received fewer votes than Martin Pfister in both rounds of the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-8-diverseqwen", "annotations": [{"type": 3, "text": "Markus Ritter received fewer votes than Martin Pfister in both rounds of the election.", "start": 0, "id": "gvpl115h"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827213, "time_last_accessed": 1752827201}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Norway, led by Simen Tiller, J\u00f8rgen Graabak, Jens Lur\u00e5s Oftebro, and Jarl Magnus Riiber, finished with a time of 50:35.5.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-21-attention", "annotations": [{"type": 1, "text": "Norway, led by Simen Tiller, J\u00f8rgen Graabak, Jens Lur\u00e5s Oftebro, and Jarl Magnus Riiber, finished with a time of 50:35.5.", "start": 0, "id": "05klmg3n"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827238, "time_last_accessed": 1752827213}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister from The Centre party received 122 votes in the first round.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-16-diversellama", "annotations": [{"type": 0, "text": "Martin Pfister from The Centre", "start": 0, "id": "1ddkgp1e"}, {"type": 0, "text": "first round.", "start": 63, "id": "wzbfpnra"}, {"type": 0, "text": "Martin Pfister from The Centre party", "start": 0, "id": "c81359xk"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": false}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827271, "time_last_accessed": 1752827238}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The total number of valid votes remained constant at 245 in both the first and second rounds.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-3-diversegemma", "annotations": [{"type": 3, "text": "The total number of valid votes remained constant at 245 in both the first and second rounds.", "start": 0, "id": "uy4dm9n8"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827292, "time_last_accessed": 1752827271}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The total number of valid votes cast in both rounds of the 2025 Swiss Federal Council election was 490.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-6-diverseqwen", "annotations": [{"type": 3, "text": "The total number of valid votes cast in both rounds of the 2025 Swiss Federal Council election was 490.", "start": 0, "id": "kglrqjtu"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827305, "time_last_accessed": 1752827292}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Markus Ritter received fewer votes than Martin Pfister in both rounds.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-18-diversellama", "annotations": [{"type": 3, "text": "Markus Ritter received fewer votes than Martin Pfister in both rounds.", "start": 0, "id": "isgajnx6"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827325, "time_last_accessed": 1752827305}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister's round_2 votes increased from 122 to 134, a higher gain than Markus Ritter's increase from 105 to 110.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-13-diversedeepseek", "annotations": [{"type": 3, "text": "Martin Pfister's round_2 votes increased from 122 to 134, a higher gain than Markus Ritter's increase from 105 to 110.", "start": 0, "id": "y5q6phfn"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827345, "time_last_accessed": 1752827325}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister received 122 votes in round_1.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-11-diversedeepseek", "annotations": [{"type": 3, "text": "Martin Pfister received 122 votes in round_1.", "start": 0, "id": "jt4u7e9b"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827358, "time_last_accessed": 1752827345}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The total valid votes in both rounds remained constant at 245.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-14-diversedeepseek", "annotations": [{"type": 3, "text": "The total valid votes in both rounds remained constant at 245.", "start": 0, "id": "ymtbt73v"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827368, "time_last_accessed": 1752827358}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "There are two candidates from The Centre party participating in the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-20-diversellama", "annotations": [{"type": 3, "text": "There are two candidates from The Centre party participating in the election.", "start": 0, "id": "fmm407xl"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827380, "time_last_accessed": 1752827368}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "There were no invalid or blank votes cast in either round of the 2025 Swiss Federal Council election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-9-diverseqwen", "annotations": [{"type": 3, "text": "There were no invalid or blank votes cast in either round of the 2025 Swiss Federal Council election.", "start": 0, "id": "n9q6djww"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827399, "time_last_accessed": 1752827380}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister received the highest number of votes in round 2 with 134 votes.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-7-diverseqwen", "annotations": [{"type": 3, "text": "Martin Pfister received the highest number of votes in round 2 with 134 votes.", "start": 0, "id": "66lcjoni"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827415, "time_last_accessed": 1752827399}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The total number of valid votes cast in both rounds is 490.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-17-diversellama", "annotations": [{"type": 3, "text": "The total number of valid votes cast in both rounds is 490.", "start": 0, "id": "micgxxsi"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": true}], "options": [], "text_fields": [], "time_last_saved": 1752827445, "time_last_accessed": 1752827415}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The absolute majority required to win the election was 123 votes in both rounds.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-5-diversegemma", "annotations": [{"type": 3, "text": "The absolute majority required to win the election was 123 votes in both rounds.", "start": 0, "id": "mzvcjxrx"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827468, "time_last_accessed": 1752827445}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Markus Ritter received the lowest number of votes among The Centre candidates with 105 votes in round_1.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-12-diversedeepseek", "annotations": [{"type": 3, "text": "Markus Ritter received the lowest number of votes among The Centre candidates with 105 votes in round_1.", "start": 0, "id": "fj7qb0gh"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827483, "time_last_accessed": 1752827468}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "There were no invalid or blank votes cast in either round of the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-4-diversegemma", "annotations": [{"type": 3, "text": "There were no invalid or blank votes cast in either round of the election.", "start": 0, "id": "fqq2iuaz"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827492, "time_last_accessed": 1752827483}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "The absolute majority required to win was 123 votes in both rounds of the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-10-diverseqwen", "annotations": [{"type": 3, "text": "The absolute majority required to win was 123 votes in both rounds of the election.", "start": 0, "id": "pz22celr"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": true}], "options": [], "text_fields": [], "time_last_saved": 1752827501, "time_last_accessed": 1752827492}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister received 122 votes in the first round of the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-1-diversegemma", "annotations": [{"type": 3, "text": "Martin Pfister received 122 votes in the first round of the election.", "start": 0, "id": "mmsdoxu2"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827513, "time_last_accessed": 1752827501}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "Martin Pfister received more votes in the second round (134) than in the first round (122).", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-2-diversegemma", "annotations": [{"type": 3, "text": "Martin Pfister received more votes in the second round (134) than in the first round (122).", "start": 0, "id": "yutese9o"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827526, "time_last_accessed": 1752827513}
{"dataset": "t2t", "split": "test", "example_idx": 56, "output": "There were no invalid or blank votes in either round of the election.", "metadata": {"annotator_instructions": "In this task, you will annotate outputs of an automatic text generation system. For each example, you will see a **table** on the left side and a corresponding generated **claim about the table** on the right side.\n<br>\n\nYour first task is to **mark factual errors in the claim**. Check closely the validity of the claim **with respect to the table**.\n\nThere are four types of errors that you can mark in the generated text:\n\n- <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Incorrect</b></span>: The fact in the text contradicts information in the table.\n- <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Not checkable</b></span>: The fact in the text cannot be checked given the table.\n- <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Misleading</b></span>: The fact in the text is misleading in the given context.\n- <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\"><b>Other</b></span>: There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.).\n<br>\n\nMark the errors by clicking the appropriate error category and dragging your mouse over the text, **highlighting the error span**. You can remove highlights by right-clicking them, if needed.\n<br>\n\nAdditionally, **disregarding the errors you found, mark the depth of the claim** by checking the appropriate box:\n\n* Claim is **poor quality**: The claim is hard to understand or nonsensical.\n* Claim is **boring**: The claim states an obvious thing you would know by just glancing at the table.\n* Claim is **informative**: You learned something relatively basic from the table.\n* Claim is **insightful**: The claim is non-trivial and does some reasoning over the table.\n<br><br>\n\n<div style=\"background-color: rgb(240, 240, 240);\"><div style=\"background-color: rgb(196, 196, 196);\"><b>Example:</b></div>\n\n<br><i>2024 Summer Olympics medal table</i>\n\n<table style=\"width: 33em; border: 1px solid black;\"><tr><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"> <i>Rank</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>NOC</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Gold</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Silver</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Bronze</i></th><th style=\"border-top: 1px solid black; border-bottom: 1px solid black;\"><i>Total</i> </th></tr><tr><td> <i>1</i></td><td><i>United States</i></td><td><i>40</i></td><td><i>44</i></td><td><i>42</i></td><td><i>126</i> </td></tr><tr><td> <i>2</i></td><td><i>China</i></td><td><i>40</i></td><td><i>27</i></td><td><i>24</i></td><td><i>91</i> </td></tr><tr><td style=\"border-bottom: 1px solid black;\"> <i>3</i></td><td style=\"border-bottom: 1px solid black;\"><i>Japan</i></td><td style=\"border-bottom: 1px solid black;\"><i>20</i></td><td style=\"border-bottom: 1px solid black;\"><i>12</i></td><td style=\"border-bottom: 1px solid black;\"><i>13</i></td><td style=\"border-bottom: 1px solid black;\"><i>45</i> </td></tr></table><br>\n\n<i>At the 2024 Olympics <span style=\"color: rgb(148, 103, 189); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">in Paris</span>, <span style=\"color: rgb(230, 171, 2); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">China got the most gold medals</span> and placed <span style=\"color: rgb(214, 39, 40); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">first</span> in the <span style=\"color: rgb(100, 100, 100); text-decoration: underline; text-decoration-thickness: 4px; text-decoration-skip-ink: none\">the</span> overall country ranking.</i>\n\n<i><br><br>[<i>x</i>] Claim is insightful</i>\n\n&nbsp;</div>\n<br>\n\nOnce you\u2019re done with both tasks, click the **Mark example as complete** button (you can still update the annotation later).\n\nYou can submit your annotations once they are all marked as complete.", "final_message": "Your annotations have been submitted.\n\nYour Prolific completion code is **CK388WFU**\n\nYou can return directly to Prolific using this URL: [https://app.prolific.com/submissions/complete?cc=CK388WFU](https://app.prolific.com/submissions/complete?cc=CK388WFU)", "examples_per_batch": 63, "annotators_per_example": 1, "idle_time": 120, "annotation_granularity": "words", "annotation_overlap_allowed": true, "service": "prolific", "sort_order": "sort-example-ids-shuffle-setups", "annotation_span_categories": [{"name": "Incorrect", "color": "rgb(214, 39, 40)", "description": "The fact in the text contradicts the data."}, {"name": "Not checkable", "color": "rgb(148, 103, 189)", "description": "The fact in the text cannot be checked given the data."}, {"name": "Misleading", "color": "rgb(230, 171, 2)", "description": "The fact in the text is misleading in the given context."}, {"name": "Other", "color": "rgb(127, 127, 127)", "description": "There\u2019s some other problem (grammar, style, relevance, repetitiveness etc.)."}], "flags": ["Claim is <b>poor quality</b>: The claim is hard to understand or nonsensical.", "Claim is <b>boring</b>: The claim states an obvious thing you would know by just glancing at the table.", "Claim is <b>informative</b>: You learned something relatively basic from the table.", "Claim is <b>insightful</b>: The claim is non-trivial and does some reasoning over the table."], "options": [], "text_fields": [], "annotator_id": "58954e2dc88c680001dd4b7e", "annotator_group": 0, "campaign_id": "t2t-freshtab-july", "start_timestamp": 1752825974.0, "end_timestamp": 1752827558.0}, "setup_id": "claim-15-diversedeepseek", "annotations": [{"type": 3, "text": "There were no invalid or", "start": 0, "id": "jnbia4x6"}, {"type": 3, "text": "election.", "start": 60, "id": "h2uxrest"}, {"type": 3, "text": "were no invalid or blank votes in either round of the elec", "start": 6, "id": "sucityu8"}], "flags": [{"label": "Claim is poor quality: The claim is hard to understand or nonsensical.", "value": false}, {"label": "Claim is boring: The claim states an obvious thing you would know by just glancing at the table.", "value": false}, {"label": "Claim is informative: You learned something relatively basic from the table.", "value": true}, {"label": "Claim is insightful: The claim is non-trivial and does some reasoning over the table.", "value": false}], "options": [], "text_fields": [], "time_last_saved": 1752827553, "time_last_accessed": 1752827549}
